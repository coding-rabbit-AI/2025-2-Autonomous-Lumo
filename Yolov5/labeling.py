import torch
import cv2
import os
import numpy as np
from tqdm import tqdm

# ==========================================
# [ì„¤ì • êµ¬ì—­] ì—¬ê¸°ì— ê²½ë¡œë¥¼ ë§ì¶°ì£¼ì„¸ìš”!
# ==========================================
IMAGE_DIR = "C:\\Users\\sungb\\Downloads\\251123_traffic-images\\traffic_images\\train\\images"    # ë¼ë²¨ë§í•  ì‚¬ì§„ í´ë”
LABEL_DIR = "C:\\Users\\sungb\\Downloads\\251123_traffic-images\\traffic_images\\train\\labels"       # ë¼ë²¨ ì €ì¥í•  í´ë”
CONF_THRES = 0.5                   # ì •í™•ë„ 50% ì´ìƒë§Œ ì¸ì •
IGNORE_BOTTOM_RATIO = 0.85         # í™”ë©´ í•˜ë‹¨ 15% (0.85~1.0)ì— ìˆëŠ” ê±´ 'ì†'ìœ¼ë¡œ ë³´ê³  ë¬´ì‹œ
# ==========================================

def is_red_or_green(img_roi):
    """
    ì‹ í˜¸ë“± ì˜ì—­(ROI)ì„ ì˜ë¼ë‚´ì„œ ë¹¨ê°„ë¶ˆì¸ì§€ ì´ˆë¡ë¶ˆì¸ì§€ íŒë³„í•˜ëŠ” í•¨ìˆ˜
    Return: 1(Red), 2(Green), or None(íŒë³„ë¶ˆê°€)
    """
    hsv = cv2.cvtColor(img_roi, cv2.COLOR_BGR2HSV)
    
    # 1. ë¹¨ê°„ìƒ‰ ë²”ìœ„ ì •ì˜ (HSV)
    lower_red1 = np.array([0, 70, 50])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([170, 70, 50])
    upper_red2 = np.array([180, 255, 255])
    
    mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask_red = mask_red1 + mask_red2
    
    # 2. ì´ˆë¡ìƒ‰ ë²”ìœ„ ì •ì˜ (HSV)
    lower_green = np.array([35, 70, 50])
    upper_green = np.array([90, 255, 255])
    mask_green = cv2.inRange(hsv, lower_green, upper_green)
    
    # í”½ì…€ ìˆ˜ ì„¸ê¸°
    red_pixels = cv2.countNonZero(mask_red)
    green_pixels = cv2.countNonZero(mask_green)
    total_pixels = img_roi.shape[0] * img_roi.shape[1]
    
    if total_pixels == 0: return None

    # ë¹„ìœ¨ ê³„ì‚° (ë¹¨ê°•ì´ë‚˜ ì´ˆë¡ì´ ì „ì²´ì˜ 10% ì´ìƒì¼ ë•Œë§Œ ì¸ì •)
    red_ratio = red_pixels / total_pixels
    green_ratio = green_pixels / total_pixels
    
    if red_ratio > 0.1 and red_ratio > green_ratio:
        return 1  # Red Light (User ID: 1)
    elif green_ratio > 0.1 and green_ratio > red_ratio:
        return 2  # Green Light (User ID: 2)
    
    return None # ìƒ‰ê¹”ì´ ì•ˆ ë³´ì´ë©´(êº¼ì§„ ì‹ í˜¸ë“± ë“±) ë¬´ì‹œ

def run_auto_labeling():
    os.makedirs(LABEL_DIR, exist_ok=True)

    # 1. ê³ ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ (yolov5x)
    print("â³ AI ë¼ë²¨ë§ ì „ë¬¸ê°€(YOLOv5x)ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘... (ì‹œê°„ì´ ì¢€ ê±¸ë¦½ë‹ˆë‹¤)")
    model = torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True)
    
    # COCO í´ë˜ìŠ¤ ê¸°ì¤€: 0(ì‚¬ëŒ), 9(ì‹ í˜¸ë“±), 11(ì •ì§€í‘œì§€íŒ)
    model.classes = [0, 9, 11] 

    # ì´ë¯¸ì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    image_files = [f for f in os.listdir(IMAGE_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    print(f"ğŸš€ ì´ {len(image_files)}ì¥ ì²˜ë¦¬ ì‹œì‘!")

    count = 0
    
    for img_file in tqdm(image_files):
        img_path = os.path.join(IMAGE_DIR, img_file)
        
        # ì´ë¯¸ì§€ ì½ê¸° (OpenCV)
        img0 = cv2.imread(img_path)
        if img0 is None: continue
        h, w, _ = img0.shape

        # YOLO ì¶”ë¡ 
        results = model(img_path)
        
        detections = []
        
        # ê°ì§€ëœ ë¬¼ì²´ ë¶„ì„
        if len(results.xywhn[0]) > 0:
            for *xywh, conf, cls in results.xywhn[0]:
                if conf < CONF_THRES: continue
                
                # [í•„í„°ë§ 1] ì†(Hand) ì œê±°: ì¤‘ì‹¬ì  yì¢Œí‘œê°€ í™”ë©´ í•˜ë‹¨ì— ìˆìœ¼ë©´ ë¬´ì‹œ
                y_center = xywh[1].item()
                if y_center > IGNORE_BOTTOM_RATIO:
                    continue

                coco_class = int(cls)
                user_class = -1 # ì´ˆê¸°í™”
                
                # [ë§¤í•‘ ë¡œì§] COCO ID -> User ID ë³€í™˜
                if coco_class == 0:     # COCO Person
                    user_class = 0      # -> User Person
                
                elif coco_class == 11:  # COCO Stop Sign
                    user_class = 3      # -> User Stop Sign
                
                elif coco_class == 9:   # COCO Traffic Light
                    # [ìƒ‰ìƒ ë¶„ì„] ì¢Œí‘œë¥¼ í”½ì…€ ë‹¨ìœ„ë¡œ ë³€í™˜í•´ì„œ ìë¥´ê¸°
                    x_c, y_c, bbox_w, bbox_h = xywh
                    x1 = int((x_c - bbox_w / 2) * w)
                    y1 = int((y_c - bbox_h / 2) * h)
                    x2 = int((x_c + bbox_w / 2) * w)
                    y2 = int((y_c + bbox_h / 2) * h)
                    
                    # ì´ë¯¸ì§€ ë²”ìœ„ ë²—ì–´ë‚˜ì§€ ì•Šê²Œ í´ë¨í•‘
                    x1, y1 = max(0, x1), max(0, y1)
                    x2, y2 = min(w, x2), min(h, y2)
                    
                    roi = img0[y1:y2, x1:x2]
                    
                    if roi.size > 0:
                        color_id = is_red_or_green(roi)
                        if color_id is not None:
                            user_class = color_id # 1(Red) or 2(Green)
                        else:
                            continue # ìƒ‰ê¹” êµ¬ë¶„ ì•ˆ ë˜ë©´ ì €ì¥ ì•ˆ í•¨ (ì„ íƒì‚¬í•­)
                    else:
                        continue

                # ìœ íš¨í•œ í´ë˜ìŠ¤ë©´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                if user_class != -1:
                    line = f"{user_class} {xywh[0]:.6f} {xywh[1]:.6f} {xywh[2]:.6f} {xywh[3]:.6f}\n"
                    detections.append(line)

        # txt íŒŒì¼ ì“°ê¸°
        txt_path = os.path.join(LABEL_DIR, os.path.splitext(img_file)[0] + ".txt")
        with open(txt_path, 'w') as f:
            f.writelines(detections)
            
        if len(detections) > 0:
            count += 1

    print(f"\nâœ… ì™„ë£Œ! {count}ê°œ ì´ë¯¸ì§€ ë¼ë²¨ë§ ë.")
    print(f"ğŸ‘‰ 'labelImg'ë¥¼ ì¼œì„œ í™•ì¸í•´ë³´ì„¸ìš”. (Speed Limitì€ ì§ì ‘ ì¶”ê°€í•´ì•¼ í•¨)")

if __name__ == "__main__":
    run_auto_labeling()